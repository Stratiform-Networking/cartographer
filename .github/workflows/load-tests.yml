name: Load Tests

# This workflow runs load tests against Cartographer services:
# - Nightly at 2 AM UTC (capacity discovery: find max sustainable load)
# - On-demand via workflow_dispatch (capacity discovery or fixed load)
#
# CAPACITY DISCOVERY (Default - Recommended):
#   Automatically finds system capacity by ramping load until performance degrades.
#   Answers: "What can my system handle right now?"
#   
#   Algorithm:
#     1. Start with initial_users (default: 10)
#     2. Add ramp_step users (default: +10) every ramp_interval seconds (default: 90s)
#     3. Monitor: P95 latency < 200ms AND error rate < 1%
#     4. Stop when thresholds exceeded or max_users reached
#     5. Report the "knee point" = maximum sustainable capacity
#
#   Configuration:
#     - Initial Users:     10 (starting point)
#     - Ramp Step:         +10 users per interval
#     - Ramp Interval:     90s (1.5 minutes between ramps)
#     - Max Users:         200 (safety limit)
#     - P95 Threshold:     200ms
#     - Error Threshold:   1%
#
# FIXED LOAD (Legacy):
#   Traditional load test with fixed user count and duration.
#   
#   Profiles:
#     Light:    10-25 users,  1-2/s spawn,  60-120s   (Quick smoke test)
#     Moderate: 50-100 users, 5-10/s spawn, 300-600s  (Baseline performance)
#     High:     100-200 users, 10-20/s spawn, 900-1800s (Stress test)

on:
  # Run on demand via workflow_dispatch
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Test type'
        required: false
        default: 'capacity_discovery'
        type: choice
        options:
          - capacity_discovery
          - fixed_load
      users:
        description: '[Fixed Load] Number of concurrent users (moderate: 50-100, high: 100-200)'
        required: false
        default: '100'
        type: string
      spawn_rate:
        description: 'User spawn rate per second (recommended: 5-10)'
        required: false
        default: '5'
        type: string
      duration:
        description: '[Fixed Load] Test duration in seconds (moderate: 300-600, high: 900-1800)'
        required: false
        default: '300'
        type: string
      ramp_initial_users:
        description: '[Capacity Discovery] Initial users'
        required: false
        default: '10'
        type: string
      ramp_step:
        description: '[Capacity Discovery] Users to add per step'
        required: false
        default: '10'
        type: string
      ramp_interval:
        description: '[Capacity Discovery] Seconds between ramps'
        required: false
        default: '90'
        type: string
      ramp_max_users:
        description: '[Capacity Discovery] Maximum users before stopping'
        required: false
        default: '200'
        type: string
      service:
        description: 'Service to test (all, auth, health, metrics, assistant, notifications)'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - auth
          - health
          - metrics
          - assistant
          - notifications
  
  # Run nightly at 2 AM UTC with capacity discovery
  schedule:
    - cron: '0 2 * * *'
  
  # Optionally run on specific branches/tags
  # push:
  #   tags:
  #     - 'v*'

jobs:
  load-test:
    runs-on: ubuntu-latest
    timeout-minutes: 45  # Increased for longer load tests
    
    # Use service containers for dependencies
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: cartographer
          POSTGRES_PASSWORD: cartographer_dev_password
          POSTGRES_DB: cartographer_auth
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-load-tests-${{ hashFiles('load-tests/requirements.txt', '*/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-load-tests-
            ${{ runner.os }}-pip-
      
      # Install all service dependencies
      - name: Install backend dependencies
        working-directory: backend
        run: pip install -r requirements.txt
      
      - name: Install auth-service dependencies
        working-directory: auth-service
        run: pip install -r requirements.txt
      
      - name: Install health-service dependencies
        working-directory: health-service
        run: pip install -r requirements.txt
      
      - name: Install metrics-service dependencies
        working-directory: metrics-service
        run: pip install -r requirements.txt
      
      - name: Install assistant-service dependencies
        working-directory: assistant-service
        run: pip install -r requirements.txt
      
      - name: Install notification-service dependencies
        working-directory: notification-service
        run: pip install -r requirements.txt
      
      - name: Install load test dependencies
        working-directory: load-tests
        run: pip install -r requirements.txt
      
      # Set up environment variables
      - name: Create environment files
        run: |
          # Auth service
          cat > auth-service/.env << EOF
          DATABASE_URL=postgresql+asyncpg://cartographer:cartographer_dev_password@localhost:5432/cartographer_auth
          JWT_SECRET=test_jwt_secret_for_load_testing_only
          JWT_ALGORITHM=HS256
          JWT_EXPIRATION_HOURS=24
          ALLOW_OPEN_REGISTRATION=false
          RESEND_API_KEY=""
          RESEND_FROM_EMAIL=""
          EOF
          
          # Health service
          cat > health-service/.env << EOF
          AUTH_SERVICE_URL=http://localhost:8002
          METRICS_SERVICE_URL=http://localhost:8003/api/metrics
          REDIS_URL=redis://localhost:6379
          EOF
          
          # Metrics service
          cat > metrics-service/.env << EOF
          AUTH_SERVICE_URL=http://localhost:8002
          REDIS_URL=redis://localhost:6379
          EOF
          
          # Assistant service
          cat > assistant-service/.env << EOF
          AUTH_SERVICE_URL=http://localhost:8002
          METRICS_SERVICE_URL=http://localhost:8003/api/metrics
          OPENAI_API_KEY=""
          ANTHROPIC_API_KEY=""
          GOOGLE_API_KEY=""
          GEMINI_API_KEY=""
          OLLAMA_BASE_URL=""
          EOF
          
          # Notification service
          cat > notification-service/.env << EOF
          DATABASE_URL=postgresql+asyncpg://cartographer:cartographer_dev_password@localhost:5432/cartographer_notifications
          AUTH_SERVICE_URL=http://localhost:8002
          REDIS_URL=redis://localhost:6379
          RESEND_API_KEY=""
          RESEND_FROM_EMAIL=""
          DISCORD_BOT_TOKEN=""
          DISCORD_PUBLIC_KEY=""
          DISCORD_APPLICATION_ID=""
          EOF
          
          # Backend
          cat > backend/.env << EOF
          DATABASE_URL=postgresql+asyncpg://cartographer:cartographer_dev_password@localhost:5432/cartographer
          AUTH_SERVICE_URL=http://localhost:8002
          HEALTH_SERVICE_URL=http://localhost:8001
          METRICS_SERVICE_URL=http://localhost:8003
          ASSISTANT_SERVICE_URL=http://localhost:8004
          NOTIFICATION_SERVICE_URL=http://localhost:8005
          FRONTEND_DIST_PATH=frontend/dist
          DISABLE_DOCS=false
          EOF
      
      # Create databases
      - name: Create databases
        run: |
          # Install PostgreSQL client
          sudo apt-get update
          sudo apt-get install -y postgresql-client
          
          # Wait for PostgreSQL to be ready
          until pg_isready -h localhost -p 5432 -U cartographer; do
            echo "Waiting for PostgreSQL..."
            sleep 2
          done
          
          # Create additional databases (cartographer_auth already exists from service definition)
          PGPASSWORD=cartographer_dev_password psql -h localhost -U cartographer -d cartographer_auth -c "CREATE DATABASE cartographer_notifications;"
          PGPASSWORD=cartographer_dev_password psql -h localhost -U cartographer -d cartographer_auth -c "CREATE DATABASE cartographer;"
          
          echo "âœ“ All databases created"
      
      # Run database migrations
      - name: Run auth service migrations
        working-directory: auth-service
        run: |
          alembic upgrade head
        env:
          DATABASE_URL: postgresql+asyncpg://cartographer:cartographer_dev_password@localhost:5432/cartographer_auth
      
      - name: Run notification service migrations
        working-directory: notification-service
        run: |
          alembic upgrade head
        env:
          DATABASE_URL: postgresql+asyncpg://cartographer:cartographer_dev_password@localhost:5432/cartographer_notifications
      
      # Create test owner account
      - name: Create test owner account
        working-directory: auth-service
        run: |
          python - << 'PYTHON_SCRIPT'
          import asyncio
          from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
          from sqlalchemy.orm import sessionmaker
          from app.services.auth_service import auth_service
          from app.models import OwnerSetupRequest
          
          async def create_owner():
              engine = create_async_engine(
                  "postgresql+asyncpg://cartographer:cartographer_dev_password@localhost:5432/cartographer_auth"
              )
              async_session = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)
              
              async with async_session() as session:
                  request = OwnerSetupRequest(
                      username="loadtest_admin",
                      first_name="Load",
                      last_name="Test",
                      email="loadtest@example.com",
                      password="LoadTest123!"
                  )
                  await auth_service.setup_owner(session, request)
                  print("âœ“ Test owner account created: loadtest_admin")
              
              await engine.dispose()
          
          asyncio.run(create_owner())
          PYTHON_SCRIPT
      
      # Start all microservices in background
      - name: Start auth service
        working-directory: auth-service
        run: |
          uvicorn app.main:app --host 0.0.0.0 --port 8002 --log-level warning &
          echo $! > /tmp/auth-service.pid
        env:
          DATABASE_URL: postgresql+asyncpg://cartographer:cartographer_dev_password@localhost:5432/cartographer_auth
          JWT_SECRET: test_jwt_secret_for_load_testing_only
          JWT_ALGORITHM: HS256
          JWT_EXPIRATION_HOURS: 24
      
      - name: Start health service
        working-directory: health-service
        run: |
          uvicorn app.main:app --host 0.0.0.0 --port 8001 --log-level warning &
          echo $! > /tmp/health-service.pid
        env:
          AUTH_SERVICE_URL: http://localhost:8002
          METRICS_SERVICE_URL: http://localhost:8003/api/metrics
          REDIS_URL: redis://localhost:6379
      
      - name: Start metrics service
        working-directory: metrics-service
        run: |
          uvicorn app.main:app --host 0.0.0.0 --port 8003 --log-level warning &
          echo $! > /tmp/metrics-service.pid
        env:
          AUTH_SERVICE_URL: http://localhost:8002
          REDIS_URL: redis://localhost:6379
      
      - name: Start assistant service
        working-directory: assistant-service
        run: |
          uvicorn app.main:app --host 0.0.0.0 --port 8004 --log-level warning &
          echo $! > /tmp/assistant-service.pid
        env:
          AUTH_SERVICE_URL: http://localhost:8002
          METRICS_SERVICE_URL: http://localhost:8003/api/metrics
      
      - name: Start notification service
        working-directory: notification-service
        run: |
          uvicorn app.main:app --host 0.0.0.0 --port 8005 --log-level warning &
          echo $! > /tmp/notification-service.pid
        env:
          DATABASE_URL: postgresql+asyncpg://cartographer:cartographer_dev_password@localhost:5432/cartographer_notifications
          AUTH_SERVICE_URL: http://localhost:8002
          REDIS_URL: redis://localhost:6379
      
      - name: Start backend
        working-directory: backend
        run: |
          uvicorn app.main:app --host 0.0.0.0 --port 8000 --log-level warning &
          echo $! > /tmp/backend.pid
        env:
          DATABASE_URL: postgresql+asyncpg://cartographer:cartographer_dev_password@localhost:5432/cartographer
          AUTH_SERVICE_URL: http://localhost:8002
          HEALTH_SERVICE_URL: http://localhost:8001
          METRICS_SERVICE_URL: http://localhost:8003
          ASSISTANT_SERVICE_URL: http://localhost:8004
          NOTIFICATION_SERVICE_URL: http://localhost:8005
      
      # Wait for services to be ready
      - name: Wait for services to start
        run: |
          echo "Waiting for services to be ready..."
          
          # Function to check if service is ready
          check_service() {
            local url=$1
            local name=$2
            local max_attempts=30
            local attempt=0
            
            while [ $attempt -lt $max_attempts ]; do
              if curl -s -f "$url" > /dev/null 2>&1; then
                echo "âœ“ $name is ready"
                return 0
              fi
              echo "  Waiting for $name... (attempt $((attempt + 1))/$max_attempts)"
              sleep 2
              attempt=$((attempt + 1))
            done
            
            echo "âœ— $name failed to start"
            return 1
          }
          
          # Check all services
          check_service "http://localhost:8002/healthz" "Auth Service"
          check_service "http://localhost:8001/healthz" "Health Service"
          check_service "http://localhost:8003/healthz" "Metrics Service"
          check_service "http://localhost:8004/healthz" "Assistant Service"
          check_service "http://localhost:8005/healthz" "Notification Service"
          check_service "http://localhost:8000/healthz" "Backend"
          
          echo "All services are ready!"
      
      # Run load tests
      - name: Run load tests
        working-directory: load-tests
        run: |
          TEST_TYPE="${{ github.event.inputs.test_type || 'capacity_discovery' }}"
          SERVICE="${{ github.event.inputs.service || 'all' }}"
          
          echo "ðŸ§ª Starting load tests..."
          echo "  Test Type: $TEST_TYPE"
          echo "  Service: $SERVICE"
          echo ""
          
          if [ "$TEST_TYPE" = "capacity_discovery" ]; then
            # Capacity Discovery Mode
            RAMP_INITIAL="${{ github.event.inputs.ramp_initial_users || '10' }}"
            RAMP_STEP="${{ github.event.inputs.ramp_step || '10' }}"
            RAMP_INTERVAL="${{ github.event.inputs.ramp_interval || '90' }}"
            RAMP_MAX="${{ github.event.inputs.ramp_max_users || '200' }}"
            SPAWN_RATE="${{ github.event.inputs.spawn_rate || '5' }}"
            
            echo "ðŸ” CAPACITY DISCOVERY MODE"
            echo "  Initial Users:  $RAMP_INITIAL"
            echo "  Ramp Step:      +$RAMP_STEP users every ${RAMP_INTERVAL}s"
            echo "  Max Users:      $RAMP_MAX"
            echo "  Spawn Rate:     $SPAWN_RATE/s"
            echo "  Stop when:      P95 > 200ms OR Error rate > 1%"
            echo ""
            
            # Run capacity discovery test using locust directly
            locust -f locustfile_capacity_discovery.py \
              --host http://localhost:8000 \
              --html capacity_discovery_report.html \
              --headless \
              --only-summary \
              --stop-timeout 10
            
          else
            # Fixed Load Mode (legacy)
            USERS="${{ github.event.inputs.users || '50' }}"
            SPAWN_RATE="${{ github.event.inputs.spawn_rate || '5' }}"
            DURATION="${{ github.event.inputs.duration || '300' }}"
            
            echo "ðŸ“Š FIXED LOAD MODE"
            echo "  Users:       $USERS"
            echo "  Spawn Rate:  $SPAWN_RATE/s"
            echo "  Duration:    ${DURATION}s"
            echo ""
            
            python run_load_tests.py \
              --service "$SERVICE" \
              --users "$USERS" \
              --spawn-rate "$SPAWN_RATE" \
              --time "$DURATION" \
              --html load_test_report.html \
              --username loadtest_admin \
              --password "LoadTest123!"
          fi
        env:
          LOADTEST_USERNAME: loadtest_admin
          LOADTEST_PASSWORD: LoadTest123!
          RAMP_INITIAL_USERS: ${{ github.event.inputs.ramp_initial_users || '10' }}
          RAMP_STEP: ${{ github.event.inputs.ramp_step || '10' }}
          RAMP_INTERVAL: ${{ github.event.inputs.ramp_interval || '90' }}
          RAMP_MAX_USERS: ${{ github.event.inputs.ramp_max_users || '200' }}
          RAMP_P95_THRESHOLD: '200'
          RAMP_ERROR_THRESHOLD: '0.01'
          RAMP_SPAWN_RATE: ${{ github.event.inputs.spawn_rate || '5' }}
      
      # Upload results
      - name: Upload load test report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: load-test-report-${{ github.event.inputs.test_type || 'capacity_discovery' }}-${{ github.event.inputs.service || 'all' }}-${{ github.event_name == 'schedule' && format('nightly-{0}', github.run_number) || format('manual-{0}', github.run_number) }}
          path: load-tests/*_report.html
          retention-days: ${{ github.event_name == 'schedule' && 90 || 30 }}
      
      # Parse and check results for scheduled runs
      - name: Check for performance issues
        if: github.event_name == 'schedule'
        run: |
          echo "ðŸ“Š Analyzing capacity discovery results..."
          echo ""
          echo "ðŸŽ¯ Capacity Discovery Test - Nightly Run"
          echo "   Goal: Find the 'knee point' = maximum sustainable load"
          echo ""
          echo "Expected Behavior:"
          echo "  âœ“ Ramp: 10 â†’ 20 â†’ 30 â†’ ... users (+10 every 90s)"
          echo "  âœ“ Stop when: P95 > 200ms OR Error rate > 1%"
          echo "  âœ“ Report: Knee point (max capacity before degradation)"
          echo ""
          echo "Performance Thresholds:"
          echo "  âœ“ Success Rate:    >99%"
          echo "  âœ“ P95 Response:    <200ms"
          echo "  âœ“ Error Threshold: <1%"
          echo ""
          
          # Check if capacity discovery report exists
          if [ -f "load-tests/capacity_discovery_report.html" ]; then
            echo "âœ“ Capacity discovery report found"
            echo ""
            echo "ðŸ“ˆ Review the report to see:"
            echo "   â€¢ Maximum sustainable concurrent users (knee point)"
            echo "   â€¢ Performance degradation pattern"
            echo "   â€¢ Specific bottleneck (latency vs errors)"
            echo "   â€¢ Comparison with previous nightly runs"
          else
            echo "âš ï¸  Capacity discovery report not found"
          fi
          echo ""
          
          # Note: This is a placeholder for future enhancement
          # You could parse the HTML report or Locust stats to:
          # - Extract knee point automatically
          # - Compare with historical baseline
          # - Alert if capacity decreased significantly (e.g., >20%)
          # - Identify degraded endpoints
          # - Track capacity trends over time
          
          echo "âœ“ Capacity analysis complete (manual review recommended)"
      
      # Cleanup
      - name: Stop services
        if: always()
        run: |
          echo "Stopping services..."
          for pidfile in /tmp/*.pid; do
            if [ -f "$pidfile" ]; then
              pid=$(cat "$pidfile")
              if kill -0 "$pid" 2>/dev/null; then
                kill "$pid" || true
              fi
              rm "$pidfile"
            fi
          done
          echo "Services stopped"
      
      # Show summary
      - name: Test summary
        if: always()
        run: |
          echo "## Load Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Determine run type
          if [ "${{ github.event_name }}" = "schedule" ]; then
            echo "ðŸŒ™ **Run Type**: Nightly Automated Test" >> $GITHUB_STEP_SUMMARY
          else
            echo "ðŸš€ **Run Type**: Manual Trigger" >> $GITHUB_STEP_SUMMARY
          fi
          
          TEST_TYPE="${{ github.event.inputs.test_type || 'capacity_discovery' }}"
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Test Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- **Test Type**: $TEST_TYPE" >> $GITHUB_STEP_SUMMARY
          echo "- **Service**: ${{ github.event.inputs.service || 'all' }}" >> $GITHUB_STEP_SUMMARY
          
          if [ "$TEST_TYPE" = "capacity_discovery" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ðŸ” Capacity Discovery Settings" >> $GITHUB_STEP_SUMMARY
            echo "- **Initial Users**: ${{ github.event.inputs.ramp_initial_users || '10' }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Ramp Step**: +${{ github.event.inputs.ramp_step || '10' }} users" >> $GITHUB_STEP_SUMMARY
            echo "- **Ramp Interval**: ${{ github.event.inputs.ramp_interval || '90' }}s" >> $GITHUB_STEP_SUMMARY
            echo "- **Max Users**: ${{ github.event.inputs.ramp_max_users || '200' }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Spawn Rate**: ${{ github.event.inputs.spawn_rate || '5' }}/s" >> $GITHUB_STEP_SUMMARY
            echo "- **P95 Threshold**: 200ms" >> $GITHUB_STEP_SUMMARY
            echo "- **Error Threshold**: 1%" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Goal**: Find the 'knee point' = maximum sustainable capacity" >> $GITHUB_STEP_SUMMARY
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ðŸ“Š Fixed Load Settings" >> $GITHUB_STEP_SUMMARY
            echo "- **Users**: ${{ github.event.inputs.users || '50' }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Spawn Rate**: ${{ github.event.inputs.spawn_rate || '5' }}/s" >> $GITHUB_STEP_SUMMARY
            echo "- **Duration**: ${{ github.event.inputs.duration || '300' }}s (~$(( ${{ github.event.inputs.duration || '300' }} / 60 )) minutes)" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "Download the HTML report from the workflow artifacts to view detailed results." >> $GITHUB_STEP_SUMMARY
          echo "### Results" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“Š Download the HTML report from the artifacts to view detailed metrics:" >> $GITHUB_STEP_SUMMARY
          echo "- Request rates (RPS)" >> $GITHUB_STEP_SUMMARY
          echo "- Response times (p50, p95, p99)" >> $GITHUB_STEP_SUMMARY
          echo "- Failure rates" >> $GITHUB_STEP_SUMMARY
          echo "- Per-endpoint breakdown" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Add info for scheduled runs
          if [ "${{ github.event_name }}" = "schedule" ]; then
            echo "ðŸ’¡ **Tip**: If load tests fail consistently, consider:" >> $GITHUB_STEP_SUMMARY
            echo "- Reviewing service logs" >> $GITHUB_STEP_SUMMARY
            echo "- Checking for recent code changes" >> $GITHUB_STEP_SUMMARY
            echo "- Running manual tests with increased timeouts" >> $GITHUB_STEP_SUMMARY
          fi

